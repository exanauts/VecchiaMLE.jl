var documenterSearchIndex = {"docs":
[{"location":"reference/#Reference","page":"Reference","title":"Reference","text":"","category":"section"},{"location":"reference/#Contents","page":"Reference","title":"Contents","text":"Pages = [\"reference.md\"]","category":"section"},{"location":"reference/#Index","page":"Reference","title":"Index","text":"Pages = [\"reference.md\"]","category":"section"},{"location":"reference/#NonparametricVecchia.VecchiaCache","page":"Reference","title":"NonparametricVecchia.VecchiaCache","text":"Internal struct from which to fetch persisting objects in the optimization function. There is no need for a user to mess with this!\n\nFields\n\nn : Size of the problem\nM : Number of Samples\nnnzL : Number of nonzeros in L\ncolptrL : Array which indexes the beginning of each column in L\nrowsL : Row index of nonzero entries in L\ndiagL : Position of the diagonal coefficient of L\nm : Number of nonzeros in each column of L\noffsets : Number of nonzeros in hessobjvals before the block Bⱼ\nB : Vector of matrices Bⱼ, the constant blocks in the Hessian\nnnzh_tri_obj : Number of nonzeros in the lower triangular part of the Hessian of the objective\nnnzh_tri_lag : Number of nonzeros in the lower triangular part of the Hessian of the Lagrangian\nhess_obj_vals : Nonzeros of the lower triangular part of the Hessian of the objective\nbuffer : Additional buffer needed for the objective\n\n\n\n\n\n","category":"type"},{"location":"vecchia_model/","page":"Tutorials","title":"Tutorials","text":"using NonparametricVecchia\nusing LinearAlgebra\nusing SparseArrays\nusing NLPModelsIpopt\n\nn = 40\nnumber_of_samples = 100\nsamples = randn(number_of_samples, n)\n\nP = ones(n, n)\nP = tril(P)\nP = sparse(P)\nI, J, V = findnz(P)\nnlp_L = VecchiaModel(I, J, samples; format=:coo, uplo=:L)\noutput = ipopt(nlp_L)\nL = recover_factor(nlp_L, output.solution)\n\nusing NonparametricVecchia\nusing LinearAlgebra\nusing SparseArrays\nusing NLPModelsIpopt\n\nn = 40\nnumber_of_samples = 100\nsamples = randn(number_of_samples, n)\n\nP = ones(n, n)\nP = triu(P)\nP = sparse(P)\nI, J, V = findnz(P)\nnlp_U = VecchiaModel(I, J, samples; format=:coo, uplo=:U)\noutput = ipopt(nlp_U)\nU = recover_factor(nlp_U, output.solution)\n\nusing NonparametricVecchia\nusing Vecchia\nusing StaticArrays\nusing LinearAlgebra\n\n# Generate some fake data with an exponential covariance function.\n# Note that each _column_ of sim is an iid replicate, in keeping with formatting\n# standards of the many R packages for GPs. In this demonstration, n is small\n# and the number of replicates is large to demonstrate asymptotic correctness.\npts = rand(SVector{2,Float64}, 100)\nz   = randn(length(pts), 1000)\nK   = Symmetric([exp(-norm(x-y)) for x in pts, y in pts])\nsim = cholesky(K).L * z\n\n# Create a VecchiaModel using the options specified by Vecchia.jl, in\n# particular choosing an ordering (in this case RandomOrdering()) and a\n# conditioning set design (in this case KNNConditioning(10)). This also returns\n# the permutation for you to use with subsequent data operations. See the docs\n# and myriad extensions of Vecchia.jl for more information on ordering and\n# conditioning set design options.\n(perm, nlp) = VecchiaModel(pts, sim, RandomOrdering(), KNNConditioning(10);\n                           lvar_diag=fill(inv(sqrt(1.0)),  length(pts)),\n                           uvar_diag=fill(inv(sqrt(1e-2)), length(pts)),\n                           lambda=1e-3)\n\n# Now bring in some optimizers and fit the nonparametric model. This gives a U\n# such that Σ^{-1} ≈ U*U', where Σ is the covariance matrix for each column of sim.\nusing MadNLP\nresult = madnlp(nlp; tol=1e-10)\nU      = UpperTriangular(recover_factor(nlp, result.solution))\n\n# KL divergence from the true covariance:\nK_perm = K[perm, perm]\nkl     = (tr(U'*K_perm*U) - length(pts)) + (-2*logdet(U) - logdet(K_perm))\n\n# compare that with what you get from a parametric Vecchia model using the\n# correct kernel and the same permutation.\npara_vecchia = VecchiaApproximation(pts[perm], (x,y,p)->exp(-norm(x-y)), sim[perm,:];\n                                    ordering=NoPermutation())\npara_U  = rchol(para_vecchia, Float64[]).U\npara_kl = (tr(para_U'*K_perm*para_U) - length(pts)) + (-2*logdet(para_U) - logdet(K_perm))\n\nprintln(\"KL divergence with true parametric kernel:  \", para_kl)\nprintln(\"KL divergence with nonparametric estimator: \", kl)","category":"section"},{"location":"#Home","page":"Home","title":"NonparametricVecchia.jl documentation","text":"","category":"section"},{"location":"#Overview","page":"Home","title":"Overview","text":"This package computes an approximate Cholesky factorization of a covariance matrix using a Maximum Likelihood Estimation (MLE) approach. The Cholesky factor is computed via the Vecchia approximation, which is sparse and approximately banded, making it highly efficient for large-scale problems.","category":"section"},{"location":"#Installation","page":"Home","title":"Installation","text":"julia> ]\npkg> add https://github.com/exanauts/NonparametricVecchia.jl.git\npkg> test NonparametricVecchia","category":"section"}]
}
